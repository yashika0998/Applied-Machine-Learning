{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5zHl3t4qg7V"
      },
      "source": [
        "## Pipeline: Evaluate results on validation set\n",
        "\n",
        "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
        "\n",
        "In last section to fit the best few models on the full training set and then evaluate the model on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDsIsK8qg7f"
      },
      "source": [
        "### Read in data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd/gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMWN9UfJqzlN",
        "outputId": "2d85d009-a324-48dd-9e95-baa50011666a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting google drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbxPAacWrBim",
        "outputId": "e1759409-169a-4150-f227-811bbed535ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MBng7wQkqg7g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "tr_features = pd.read_csv('/content/drive/MyDrive/Summer_Learning/Ex_Files_Applied_Machine_Learning/Exercise_Files/train_features.csv')\n",
        "tr_labels = pd.read_csv('/content/drive/MyDrive/Summer_Learning/Ex_Files_Applied_Machine_Learning/Exercise_Files/train_labels.csv', header=None)\n",
        "\n",
        "val_features = pd.read_csv('/content/drive/MyDrive/Summer_Learning/Ex_Files_Applied_Machine_Learning/Exercise_Files/val_features.csv')\n",
        "val_labels = pd.read_csv('/content/drive/MyDrive/Summer_Learning/Ex_Files_Applied_Machine_Learning/Exercise_Files/val_labels.csv', header=None)\n",
        "\n",
        "te_features = pd.read_csv('/content/drive/MyDrive/Summer_Learning/Ex_Files_Applied_Machine_Learning/Exercise_Files/test_features.csv')\n",
        "te_labels = pd.read_csv('/content/drive/MyDrive/Summer_Learning/Ex_Files_Applied_Machine_Learning/Exercise_Files/test_labels.csv', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vJVuJmGqg7i"
      },
      "source": [
        "### Fit best models on full training set\n",
        "\n",
        "Results from last section:\n",
        "```\n",
        "0.76 (+/-0.116) for {'max_depth': 2, 'n_estimators': 5}\n",
        "0.796 (+/-0.119) for {'max_depth': 2, 'n_estimators': 50}\n",
        "0.803 (+/-0.117) for {'max_depth': 2, 'n_estimators': 100}\n",
        "--> 0.828 (+/-0.074) for {'max_depth': 10, 'n_estimators': 5}\n",
        "0.816 (+/-0.028) for {'max_depth': 10, 'n_estimators': 50}\n",
        "--> 0.826 (+/-0.046) for {'max_depth': 10, 'n_estimators': 100}\n",
        "0.785 (+/-0.106) for {'max_depth': 20, 'n_estimators': 5}\n",
        "0.813 (+/-0.027) for {'max_depth': 20, 'n_estimators': 50}\n",
        "0.809 (+/-0.029) for {'max_depth': 20, 'n_estimators': 100}\n",
        "0.794 (+/-0.04) for {'max_depth': None, 'n_estimators': 5}\n",
        "0.809 (+/-0.037) for {'max_depth': None, 'n_estimators': 50}\n",
        "--> 0.818 (+/-0.035) for {'max_depth': None, 'n_estimators': 100}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgZRgyunqg7j"
      },
      "outputs": [],
      "source": [
        "rf1 = RandomForestClassifier(n_estimators=5, max_depth=10)\n",
        "rf1.fit(tr_features, tr_labels.values.ravel())\n",
        "\n",
        "rf2 = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
        "rf2.fit(tr_features, tr_labels.values.ravel())\n",
        "\n",
        "rf3 = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
        "rf3.fit(tr_features, tr_labels.values.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsUtAyF3qg7l"
      },
      "source": [
        "### Evaluate models on validation set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUzmR0Vbqg7m"
      },
      "outputs": [],
      "source": [
        "for mdl in [rf1, rf2, rf3]:\n",
        "    y_pred = mdl.predict(val_features)\n",
        "    accuracy = round(accuracy_score(val_labels, y_pred), 3)\n",
        "    precision = round(precision_score(val_labels, y_pred), 3)\n",
        "    recall = round(recall_score(val_labels, y_pred), 3)\n",
        "    print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(mdl.max_depth,\n",
        "                                                                         mdl.n_estimators,\n",
        "                                                                         accuracy,\n",
        "                                                                         precision,\n",
        "                                                                         recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX95U7iqqg7o"
      },
      "source": [
        "### Evaluate the best model on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiA6TxFFqg7p",
        "outputId": "b8755bb5-3670-4cf9-88e5-a5f0998d15a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAX DEPTH: 10 / # OF EST: 100 -- A: 0.798 / P: 0.764 / R: 0.646\n"
          ]
        }
      ],
      "source": [
        "y_pred = rf2.predict(te_features)\n",
        "accuracy = round(accuracy_score(te_labels, y_pred), 3)\n",
        "precision = round(precision_score(te_labels, y_pred), 3)\n",
        "recall = round(recall_score(te_labels, y_pred), 3)\n",
        "print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(rf2.max_depth,\n",
        "                                                                     rf2.n_estimators,\n",
        "                                                                     accuracy,\n",
        "                                                                     precision,\n",
        "                                                                     recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLz_duXcqg7q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "05_07 - 05_08.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}